# Celery Worker Environment Configuration
# Phase 8: Email Service Background Task Processing
#
# Copy to .env and adjust values for your environment
# Usage: source .env && docker-compose up

# ============================================================================
# REDIS CONFIGURATION (Broker & Result Backend)
# ============================================================================

# Broker URL (task queue)
REDIS_URL=redis://redis:6379/0
REDIS_HOST=redis
REDIS_PORT=6379
REDIS_BROKER_DB=0
REDIS_PASSWORD=
REDIS_USE_SSL=false
REDIS_SSL_CERT_REQS=CERT_REQUIRED
REDIS_SSL_VERIFY_CERT=true

# Result backend (task results storage)
CELERY_RESULT_BACKEND=redis://redis:6379/1
REDIS_RESULT_HOST=redis
REDIS_RESULT_PORT=6379
REDIS_RESULT_DB=1
REDIS_RESULT_PASSWORD=
REDIS_RESULT_USE_SSL=false

# Result expiration (seconds) - Results older than this are cleaned up
CELERY_RESULT_EXPIRES=3600

# ============================================================================
# DATABASE CONFIGURATION
# ============================================================================

# PostgreSQL connection string (for email_service)
DATABASE_URL=postgresql://metabuilder:dev_password@postgres:5432/metabuilder_dev
SQLALCHEMY_DATABASE_URL=postgresql://metabuilder:dev_password@postgres:5432/metabuilder_dev
SQLALCHEMY_ECHO=false

# ============================================================================
# CELERY WORKER CONFIGURATION
# ============================================================================

# Number of concurrent worker processes (processes in pool)
# Tune based on:
# - CPU cores available
# - Expected task volume
# - Memory per task
# Default: 4 (good for development)
# Production: 1-2x CPU cores
CELERYD_CONCURRENCY=4

# Hard time limit for tasks (seconds)
# Tasks exceeding this are killed
# Default: 300 (5 minutes)
# Increase for long-running sync operations
TASK_TIMEOUT=300

# Soft time limit for tasks (seconds)
# Tasks receive SIGTERM at this limit for graceful shutdown
# Should be ~20 seconds less than hard limit
CELERY_TASK_SOFT_TIME_LIMIT=280

# Prefetch multiplier (tasks per worker before accepting new tasks)
# 1 = process one task at a time (safest)
# >1 = can lead to uneven load distribution
CELERY_WORKER_PREFETCH_MULTIPLIER=1

# Max tasks per worker before restart (memory safety)
# Worker restarts after this many tasks to prevent memory leaks
# Default: 1000
CELERY_WORKER_MAX_TASKS_PER_CHILD=1000

# Task tracking
CELERY_TRACK_STARTED=true

# Task acknowledgment mode
# false = acknowledge before execution (faster but loses tasks on worker crash)
# true = acknowledge after execution (slower but safer)
CELERY_TASK_ACKS_LATE=true

# Task serialization format
CELERY_TASK_SERIALIZER=json
CELERY_RESULT_SERIALIZER=json
CELERY_ACCEPT_CONTENT=json
CELERY_TIMEZONE=UTC
CELERY_ENABLE_UTC=true

# ============================================================================
# CELERY RETRY CONFIGURATION (Exponential Backoff)
# ============================================================================

# Enable exponential backoff for retries
CELERY_RETRY_BACKOFF=true

# Base for exponential backoff (multiply by this each retry)
CELERY_RETRY_BACKOFF_BASE=2

# Maximum backoff delay (seconds)
CELERY_RETRY_BACKOFF_MAX=600

# Default delay before first retry (seconds)
CELERY_DEFAULT_RETRY_DELAY=5

# Default max retries per task
CELERY_DEFAULT_MAX_RETRIES=5

# ============================================================================
# CELERY BEAT SCHEDULER CONFIGURATION
# ============================================================================

# Beat schedule persistence database
CELERY_BEAT_SCHEDULE_DB=/app/logs/celery-beat-schedule.db

# Beat sync interval (check for schedule changes every N seconds)
CELERY_BEAT_SYNC_INTERVAL=5

# ============================================================================
# LOGGING CONFIGURATION
# ============================================================================

# Log level for Celery (debug, info, warning, error, critical)
LOG_LEVEL=info

# Python logging configuration
PYTHONUNBUFFERED=1
PYTHONDONTWRITEBYTECODE=1

# ============================================================================
# EMAIL SERVICE CONFIGURATION
# ============================================================================

# Email service API endpoint (for HTTP requests from tasks)
EMAIL_SERVICE_URL=http://email-service:5000

# Email service health check endpoint
EMAIL_SERVICE_HEALTH_URL=http://email-service:5000/health

# ============================================================================
# TASK-SPECIFIC CONFIGURATION
# ============================================================================

# Sync task configuration
SYNC_BATCH_SIZE=100          # Messages per batch during sync
SYNC_FULL_INTERVAL_DAYS=7    # Full sync every N days
SYNC_INCREMENTAL_INTERVAL=5  # Minutes between incremental syncs

# Send task configuration
SMTP_TIMEOUT=30              # SMTP connection timeout
SMTP_RETRIES=3               # Number of SMTP retry attempts

# Delete task configuration
DELETE_BATCH_SIZE=100        # Messages per delete batch
TRASH_RETENTION_DAYS=30      # Keep trash for N days before purging

# Spam detection configuration
SPAM_CHECK_ENABLED=true
SPAM_SCORE_THRESHOLD=0.7     # Score above this = spam
SPAM_API_ENABLED=false       # Enable external API (SpamAssassin, etc.)
SPAM_API_URL=                # External spam detection API

# ============================================================================
# SECURITY CONFIGURATION
# ============================================================================

# Credential encryption key (for email passwords)
# Generate: python -c "import secrets; print(secrets.token_hex(32))"
CREDENTIAL_ENCRYPTION_KEY=your-secret-key-here

# SSL/TLS configuration for external services
SSL_VERIFY=true
SSL_CAPATH=/etc/ssl/certs

# ============================================================================
# MONITORING & OBSERVABILITY
# ============================================================================

# Flower monitoring dashboard
FLOWER_ENABLED=true
FLOWER_PORT=5555
FLOWER_PERSISTENT=true
FLOWER_MAX_TASKS=10000

# Prometheus metrics (optional)
PROMETHEUS_ENABLED=false
PROMETHEUS_PORT=8000

# ============================================================================
# RESOURCE LIMITS (Docker)
# ============================================================================

# CPU limits (cores)
DOCKER_CPU_LIMIT=2

# Memory limits (MB)
DOCKER_MEMORY_LIMIT=512
DOCKER_MEMORY_RESERVATION=256

# ============================================================================
# DEPLOYMENT MODE
# ============================================================================

# Environment: development, staging, production
ENVIRONMENT=development

# Debug mode (true = verbose logging, false = production)
DEBUG=false
